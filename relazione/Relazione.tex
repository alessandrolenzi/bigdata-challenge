\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{hyperref}

\usepackage{titling}
\newcommand{\subtitle}[1]{%
  \posttitle{%
    \par\end{center}
    \begin{center}\large#1\end{center}
    \vskip0.5em}%
}

\author{Michele Carignani, Alessandro Lenzi}
\title{Community discovery in Milan}
\subtitle{project for the course of Distributed Enabling Platforms}

\makeindex

\begin{document}

\maketitle
\tableofcontents

\begin{abstract}
The aim of the project is to analyze and then visualize telecommunication data
in order to discover real-world communities basing on the strength of connection
between different geographical areas. We implemented a pipeline of
map reduce job with the Hadoop distributed computation
environment\footnote{http://hadoop.apache.org/}.
In \ref{thedataset} and \ref{ds_analysis} of this report, we describe the original dataset
and analyze its properties. Then in \ref{aggregation}
we explain how we rearranged the data in
order to reduce the noise and improve the tractability and robustness of the
community discovery phase. Sections \ref{approaches}, \ref{mcl} will then
briefly describe two different approaches for community discovery
(finding strongly connected components and markovian clustering)
and in detail describe strategy and implementation of the latter which has
proved to give more significant results.
Finally \ref{results} will collect results and conclusion of the developed project.
\end{abstract}

%% Dataset and analysis
\input{Dataset.tex}

\input{Idea.tex}

%% How aggregated graphs are generated
\input{Aggregation.tex}


\section{Communities discovery approaches}
\label{approaches}

Once the aggregated graph is produced (as list of weighted edges) is time to compute
the communities (i.e. the clusters) over it.

Two different approaches were developed and tested. 
As we will see, the second will give the
expected results, while the first will fail.

\subsection{Tarjan Connected Components algorithm}
%todo: explain cuts
Defining the communities as connected components onto the graph\footnote{A connected component
in a graph $A = (N,E)$ is a subset of nodes $A' \in A$  s.t. each node in A' is connected to 
all the other nodes in A' 
%% todo: more formal definition?
}, the first idea was to apply Tarjan's algorithm for connected components, whose pseudo code is in \ref{alg:tarjan}.


In our initial approach, a mere visit, ordered on the arc identifier (i.e. \texttt{for i = 0 to 10000 do strongconnect(i)}) was performed. This visit, though executed with different cuts over the probability of the arcs, evidenced
a strong bias of the order of visit on the found strongly connected components.
As an example, with a cut on probability 0.005, a huge SCC is found, containing almost all nodes. Only few nodes remain
outside this CFC, and some small aggregations can be found between them.
So our second step has been achieving a visiting strategy consistent with the effective traffic measured during the day.
To do so, we used the measurements of the total activity of grids in order to establish a visiting order to be 
followed during the procedure.
\begin{figure}
\begin{verbatim}
input: graph G = (V, E)
output: set of strongly connected components (sets of vertices)
index := 0
S := empty
for each v in V do
	if (v.index is undefined) then
		strongconnect(v)
		
function strongconnect(v)
v.index := index
v.lowlink := index
index := index + 1
S.push(v)
for each (v, w) in E do
	if (w.index is undefined) then
		strongconnect(w)
		v.lowlink := min(v.lowlink, w.lowlink)
		else if (w is in S) then
			v.lowlink := min(v.lowlink, w.index)
if (v.lowlink = v.index) then
	start a new strongly connected component
	do
		w := S.pop()
		add w to current strongly connected component
	until (w = v)
	output the current strongly connected component
end function
\end{verbatim}
\caption{Tarjan Strongly Connected Components algorithm}
\label{alg:tarjan}
\end{figure}
We performed the following attempts and different visits on our graph:
\begin{enumerate}
\item Nodes visited for increasing outgoing hourly traffic, with arcs selected with increasing probability. 
\item Nodes visited for decreasing outgoing hourly traffic, with arcs ordered with increasing probability.
\item Nodes visited for decreasing outgoing hourly traffic, with arcs ordered with decreasing probability.
\item Nodes visited for increasing outgoing hourly traffic, with arcs ordered with decreasing probability.
\end{enumerate}
\begin{figure}
\centering
\includegraphics[scale=0.5]{tarjanscc.png}
\caption{Strongly connected components found with Tarjan Algorithm.From left to right, top to bottom the hours considered are 12, 13, 14, 15.
The visit has been performed with increasing hourly traffic and arcs selected with increasing probability. 
The cut has been performed at value 0.05.}
\label{fig:tarjan1}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.6]{tarjanscc2.png}
\caption{Stronglu connected components found with Tarjan Algorithms. From left to right, top to bottom the hours considered are 0, 1, 2 and 3.
The visits have been performed with increasing hourly traffic and arcs selected with increasing probability.
Cut performed at value 0.05}
\label{fig:tarjan2}
\end{figure}

The image \ref{fig:tarjan1} shows the found strongly connected components in the most trafficated hours 
of the analysis. As it is possible to notice by looking to \ref{fig:analysis}, in fact, during
these hours arcs values are very concentrated near the mean, and thus most of them will be cutted out, making
most of the strongly connected components to disappear in the most trafficated hours of the day.
The results are slightly better in less trafficated hours as shown in \ref{fig:tarjan2}, in which the variance is higher and thus a wider number
of arcs will "save himself" from the performed cutting.
In other attempts, we tried to modify the threshold so that it would save more arcs for the computation,
but we have not been able to find an appropriate threshold leading to a large enough number of clusters
and with an acceptable size.\\
In fact, in most cases, a too low threshold led to few huge connected components whilst too high led to few and very small
connected components.\\
The approach described above, in our opinion, could not lead to the desired results because of two reasons:
\begin{itemize}
\item First, the visiting order, though more meaningful, was still establishing a bias in the search of the components because
of the "paths" eliminated by the original Tarjan algorithm
\item and second, the "static" threshold did not adapt well to changing traffic along the days.
\end{itemize}
To overcome this issues, we decided to implement a small variation of the Tarjan SCC algorithm, in which visited nodes not
becoming part of a strongly connected component could be visited again while searching for others, thus increasing the
complexity of the algorithm but with the advantage of reducing the visit ordering bias.
\\
The other modification that we implemented was that of percentile-based cuts. In this approach, for every hour, the probability
distribution has been calculated and only arc probabilities in a certain percentile have been held, while the others
have been cutted as it was done before with a "static" threshold. This allows for a more fine-grained cutting, allowing
to keep more arcs also in more trafficated hours of the day.

\begin{figure}
\includegraphics[scale=0.8]{tarjan3.png}
\caption{Strongly connected components found cutting at the 99-th percentile. Hours depicted are, from left to right and from top to bottom, 12-17.}
\label{fig:tarjan3}
\end{figure}

In \ref{fig:tarjan3} this modified algorithm has been tried with a cut on the 99-th precentile. In the plot
for the SCC found in this case, it is possible to see that most of them are geographically localized (as we expected),
but still their size is very small. \\
However, only few components were able to "survive" across several hours, and are mostly localized in the outskirts 
of the city. \\
Other attempts have been made to find suitable strongly connected components, but also small modification in percentiles
led either to very noise results (with almost all zones in the same component) or to empty results. 
From this approach, we understood that
\begin{enumerate}
\item Very high cuts are needed, because of the high connectivity degree of the graph
\item The statistics of arcs probabilities, however, seem to indicate the existance of zones calling themselves significantly more frequently than others.
\item Visiting strategy has a very strong bias, and probably never considering twice the same arc could lead to eliminate some interesting strongly connected components
\item The number of components is almost always lower than the expected one, however they are uniformly spreaded along the space taken into consideration
\item In different hours, the components vary in their positions, possibly indicating different users behaviours in different hours
\item Specially during hours in which we expected less traffic, components tend to move towards the outskirts, possibly denoting clusters belonging to small towns near Milan
\item The found components are not stable during consecutive hours but they appear and disappear. In the beginning we thought this was due to the "static" cut, but the reproposition
of this behaviour with the percentile denotes that the reason must be either a very noisy dataset or high variation in the users behaviours during the day.
\end{enumerate}

As previously said in Chapter 2, all of this research led us to the conclusion that the best approach was to find a sort of "average behaviour" to analyse and
to move to a different approach, in which communities are seen as clusters. 
To do so, we chose the \emph{Markov Clustering} algorithm, which is known in litterature for the purpose of finding communities in graphs.


For a more complete dissertation on what we did using this approach for discovering communities, we invite you to refer to the attacched file \texttt{CfcSuGrafiOrari.pdf}, in Italian.

\subsection{Markov Clustering}

We then looked at a diffferent approach: Markov Clustering based on the Markov Clustering Algorithm by Stijn van Dongen\footnote{\url{http://micans.org/mcl/}}.

The idea was to reduce noise and emphasize relations in a more structured way
by multiplying the adjancy matrix of the graph by itself until the number of
non-null elements in each row is very low (reduce the number of edges) and with
values probability weight close to 1 (taking the most probable connections).

Therefore, the pseudocode of the algorith is:
\begin{figure}
%% todo: add pseudocode
\begin{verbatim}

\end{verbatim}
\caption{Markov Clustering pseudocode}
\end{figure}

%% Todo: explain the idea of flux

\input{MarkovClustering.tex}

\section{Risultati}
\label{results}



\end{document}
